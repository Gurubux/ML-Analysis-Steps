POINT ESTIMATES AND CONFIDENCE INTERVALSINFERENTIAL STATISTICS
http://hamelg.blogspot.com/2015/11/python-for-data-analysis-part-23.html?view=timeslide
-----------------------------------------------------------------------d
Inferential Analysis
	Statistical inference is the process of analyzing sample data to gain insight into the population from which the data was collected and  to investigate differences between data samples.
	For example, leading up to U.S. presidential elections it could be very useful to know the political leanings of every single eligible voter, but surveying every voter is not feasible. Instead, we could poll some subset of the population,  such as a thousand registered voters, and use that data to make inferences about the population as a whole.

-----------------------------------------------------------------------
POINT ESTIMATES
-----------------------------------------------------------------------
Point estimates are estimates of population parameters based on sample data. For instance, if we wanted to know the average age of registered voters in the U.S., we could take a survey of registered voters and then use the average age of the respondents as a point estimate of the average age of the population as a whole. The average of a sample is known as the sample mean.

Let`s investigate point estimates by generating a population of random age data and then drawing a sample from it to estimate the mean:

np.random.seed(10)
population_ages1 = stats.poisson.rvs(loc=18, mu=35, size=150000)
population_ages2 = stats.poisson.rvs(loc=18, mu=10, size=100000)
population_ages = np.concatenate((population_ages1, population_ages2))
population_ages.mean()
>>>43.002372000000001


np.random.seed(6)
sample_ages = np.random.choice(a= population_ages,
                               size=500)            # Sample 1000 values
print ( sample_ages.mean() )                         # Show sample mean
population_ages.mean() - sample_ages.mean()   # Check difference between means
>>>42.388
>>>0.61437200000000303
#Our point estimate based on a sample of 500 individuals underestimates the true population mean by 0.6 years, but it is close. 
#This illustrates an important point: we can get a fairly accurate estimate of a large population by sampling a relatively small
# subset of individuals.




random.seed(10)
population_races = (["white"]*100000) + (["black"]*50000) +\
                   (["hispanic"]*50000) + (["asian"]*25000) +\
                   (["other"]*25000)
    
demo_sample = random.sample(population_races, 1000)   # Sample 1000 values

for race in set(demo_sample):
    print( race + " proportion estimate:" )
    print( demo_sample.count(race)/1000 )
for race in set(population_races):
    print( race + " proportion estimate:" )
    print( population_races.count(race)/250000 )
hispanic proportion estimate:
0.192
white proportion estimate:
0.379
black proportion estimate:
0.231
other proportion estimate:
0.099
asian proportion estimate:
0.099
hispanic proportion estimate:
0.2
white proportion estimate:
0.4
black proportion estimate:
0.2
other proportion estimate:
0.1
asian proportion estimate:
0.1
"Notice that the proportion estimates are close to the true underlying population proportions."
-----------------------------------------------------------------------
SAMPLING DISTRIBUTIONS AND THE CENTRAL LIMIT THEOREM
-----------------------------------------------------------------------
import scipy.stats as stats
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import random
import math
# Obtaining Population ages from 18 with mean 35 and 18 with mean 10
np.random.seed(10)
population_ages1 = stats.poisson.rvs(loc=18, mu=35, size=150000)
population_ages2 = stats.poisson.rvs(loc=18, mu=10, size=100000)
population_ages = np.concatenate((population_ages1, population_ages2))
# Plot the population Histogram
pd.DataFrame(population_ages).hist(bins=58,
                                  range=(17.5,75.5),
                                  figsize=(9,9))

# Obtaining Sample ages size 500
np.random.seed(6)
sample_ages = np.random.choice(a= population_ages,
                               size=500)
# Plot the Sample Histogram
pd.DataFrame(sample_ages).hist(bins=58,
                                  range=(17.5,75.5),
                                  figsize=(9,9))


"Both the sample and population has roughly the same shape as the underlying population."

"**IMP** So we apply Central Limit theorem if Sample and Poplation do not have Normal distribution"
np.random.seed(10)
point_estimates = []         # Make empty list to hold point estimates

# Apply SAMPLING to perform the Central Limit Theorem
for x in range(200):         # Generate 200 samples
    sample = np.random.choice(a= population_ages, size=500)
    point_estimates.append( sample.mean() )
# Plot the Central Limit Theorem
pd.DataFrame(point_estimates).plot(kind="density",  # Plot sample mean density
                                   figsize=(9,9),
                                   xlim=(41,45))   

print(print( stats.skew(population_ages) )) # -0.1200
print(print( stats.skew(sample_ages) )) # -0.05622
print(print( stats.skew(point_estimates) )) # 0.16159

print(population_ages.mean()) # 43.002372
print(sample_ages.mean())  # 42.388
print(np.array(point_estimates).mean())  # 43.08678

# Check difference between means
print(population_ages.mean() - sample_ages.mean() )  # 0.61437200000000303
print(population_ages.mean() - np.array(point_estimates).mean()) # -0.08440799999999626
"the mean of the sampling distribution approaches the true population mean"


#The more samples we take, the better our estimate of the population parameter is likely to be.
-----------------------------------------------------------------------
CONFIDENCE INTERVALS
-----------------------------------------------------------------------
___________________________________________________________________________________________________________________
________________________CONFIDENCE INTERVAL - z-critical value - point estimate MEAN_________________________________
"If you KNOW THE STANDARD DEVIATION OF THE POPULATION, the margin of error is equal to:"
							 ________________
	 						/	 	  σ		/
MARGIN OF ERROR 	 =     /	z ∗ -----  /
    					  /__________√n___/		 
							where,
									σ (sigma) is the population standard deviation, ddof = 0, 
									n is sample size, and 
									z is a number known as the z-critical value, stats.norm.ppf(q = 0.975)

CONFIDENCE INTERVAL  = [ SAMPLE_MEAN  +  MARGIN OF ERROR , SAMPLE_MEAN -  MARGIN OF ERROR ]


The z-critical value is the number of standard deviations you`d have to go from the mean of the normal distribution to capture the proportion 
of the data associated with the desired confidence level. For instance, we know that roughly 95% of the data in a normal distribution lies
within 2 standard deviations of the mean, so we could use 2 as the z-critical value for a 95% confidence interval 
(although it is more exact to get z-critical values with stats.norm.ppf().).

print("MARGIN OF ERROR", stats.norm.ppf(q=0.025) ) # Find the quantile for the 2.5% cutoff # -1.95996398454 # ~ -2
print("MARGIN OF ERROR", stats.norm.ppf(q=0.975) ) # Find the quantile for the 97.5% cutoff # 1.95996398454 # ~  2


Let`s calculate a 95% confidence for our mean point estimate:
np.random.seed(10)

sample_size = 1000 # n
sample = np.random.choice(a= population_ages, size = sample_size)
sample_mean = sample.mean() # 42.523

z_critical = stats.norm.ppf(q = 0.975)  # Get the z-critical value* # z # 1.95996398454                     
pop_stdev = population_ages.std()  # Get the population standard deviation # σ
margin_of_error = z_critical * (pop_stdev/math.sqrt(sample_size)) #
confidence_interval = (sample_mean - margin_of_error,
                       sample_mean + margin_of_error)  
print(confidence_interval) #(41.703064068826833, 43.342935931173173)


# Let's create several confidence intervals and plot them to get a better sense of what it means to "capture" the true mean:
np.random.seed(12)
sample_size = 1000
intervals = []
sample_means = []

for sample in range(25):
    sample = np.random.choice(a= population_ages, size = sample_size)
    sample_mean = sample.mean()
    sample_means.append(sample_mean)
    z_critical = stats.norm.ppf(q = 0.975)  # Get the z-critical value*         
    pop_stdev = population_ages.std()  # Get the population standard deviation
    stats.norm.ppf(q = 0.025)
    margin_of_error = z_critical * (pop_stdev/math.sqrt(sample_size))
    confidence_interval = (sample_mean - margin_of_error,
                           sample_mean + margin_of_error)  
    intervals.append(confidence_interval)
>>>intervals
[(42.43806406882683, 44.07793593117317),
 (42.35506406882683, 43.99493593117317),
 (42.69006406882683, 44.32993593117317),
 (42.12106406882683, 43.76093593117317),
 ..., ...
 (42.09006406882683, 43.729935931173166),
 (43.40106406882683, 45.040935931173166),
 (41.96106406882683, 43.60093593117317),
 (42.43006406882683, 44.06993593117317)] 



# Plotting multiple Confidence interval based in comparision the true population mean = 43.0023
plt.figure(figsize=(15,9))

#Similar to confidence interval but Vertical line instead of Shade
"""plt.errorbar(x=np.arange(0.1, 50, 1), 
             y=sample_means, 
             yerr=[(top-bot)/2 for top,bot in intervals],
             fmt='o')"""
#Sample Means Line and points for 50 samples
plt.plot(np.arange(0.1, 50, 1),np.array([bot+(top-bot)/2 for top,bot in intervals]))
plt.scatter(np.arange(0.1, 50, 1),np.array([bot+(top-bot)/2 for top,bot in intervals]))

#Population Mean Line # 43.0023
plt.hlines(xmin=0, xmax=50,
           y=43.0023, 
           linewidth=2.0,
           color="red")
#Confidence Interval plot for confidence 95 or quantile 0.975
plt.fill_between(np.arange(0.1, 50, 1), [bot for top,bot in intervals],
                     [top for top,bot in intervals], alpha=0.1,
                     color="r")
___________________________________________________________________________________________________________________
________________________CONFIDENCE INTERVAL - t-critical value - point estimate MEAN_______________________________

"If you DON'T KNOW THE STANDARD DEVIATION OF THE POPULATION, the margin of error is equal to:"
							 __________________
	 						/	 	  σ		  /
MARGIN OF ERROR 	 =     /	t ∗ -----    /
    					  /__________√n_____/		 
							where,
									σ (sigma) is the Sample standard deviation, ddof = 1, 
									n is sample size, and 
									z is a number known as the t-critical value, stats.t.ppf(q = 0.975, df=n-1)

CONFIDENCE INTERVAL  = [ SAMPLE_MEAN  +  MARGIN OF ERROR , SAMPLE_MEAN -  MARGIN OF ERROR ]
	You have to use the standard deviation of your sample as a stand in when creating confidence intervals. 
Since the sample standard deviation may not match the population parameter the interval will have more error 
when you don`t know the population standard deviation. To account for this error, we use what's known as  

'T-CRITICAL VALUE' instead of the Z-CRITICAL value. 
The t-critical value is drawn from what`s known as a " t-distribution " --a distribution that closely resembles the normal distribution 
but that gets wider and wider as the sample size falls. 

The t-distribution is available in scipy.stats with the nickname "t" so we can get t-critical values with stats.t.ppf() instead of stats.norm.ppf().
------------------------------------
------------------------------------
Let`s take a new, SMALLER SAMPLE and then create a confidence interval without the population standard deviation, using the t-distribution:

np.random.seed(10)
sample_size = 25
sample = np.random.choice(a= population_ages, size = sample_size)
sample_mean = sample.mean()

t_critical = stats.t.ppf(q = 0.975, df=24)  # Get the t-critical value* 
#*Note: when using the t-distribution, you have to supply the degrees of freedom (df) UNLIKE stats.norm.ppf(q = 0.975)

print("t-critical value:")                  # Check the t-critical value
print(t_critical)                        

sample_stdev = sample.std(ddof=1)    # Get the sample standard deviation UNLIKE population_ages.std() where ddof=0
# In standard statistical practice, 
# 	ddof=1 provides an unbiased estimator of the variance of a hypothetical infinite population. 
# 	ddof=0 provides a maximum likelihood estimate of the variance for normally distributed variables.
# For sample the Std is TSS/√(n-1) instead of TSS/n And since in the Scipy formulae 
# 	the divisor used in calculations is N - ddof, where N represents the number of elements, and ddof is default 0 so passing 1 is mandatory
sigma = sample_stdev/math.sqrt(sample_size)  # Standard deviation estimate
margin_of_error = t_critical * sigma

confidence_interval = (sample_mean - margin_of_error,
                       sample_mean + margin_of_error)  

print("Confidence interval:")
print(confidence_interval)
>>>
t-critical value:
2.06389856163 # larger than z-critical value = 1.95996398454 
Confidence interval:
(37.757112737010608, 48.002887262989397)  
# The end result is a much wider confidence interval (an interval with a larger margin of error.)
# instead of (41.703064068826833, 43.342935931173173)
"Notice that the t-critical value is larger than the z-critical value we used for 95% confidence interval.
"This allows the confidence interval to CAST A LARGER NET TO MAKE UP FOR THE VARIABILITY caused by using the 
"sample standard deviation in place of the population standard deviation."

------------------------------------
------------------------------------
"If you have a large sample( > 25 ), the t-critical value will approach the z-critical value so there is 
"little difference between using the normal distribution vs. the t-distribution:"

# Check the difference between critical values with a sample size of 25 and 1000 for  t-critical and z-critical respectively
print(stats.t.ppf(q=0.975, df= 24) - stats.norm.ppf(0.975)  )
0.1039345770879665
# Check the difference between critical values with a sample size of 1000             
print(stats.t.ppf(q=0.975, df= 999) - stats.norm.ppf(0.975)  )
0.0023774765933946007

------------------------------------
------------------------------------
calculating a confidence interval using the Python function stats.t.interval():

stats.t.interval(alpha = 0.95,              # Confidence level
                 df= 24,                    # Degrees of freedom
                 loc = sample_mean,         # Sample mean
                 scale = sigma)             # Standard deviation estimate
(37.757112737010608, 48.002887262989397)  

_________________________________________________________________________________________________________________________
________________________CONFIDENCE INTERVAL - z-critical value - point estimate PROPORTION_______________________________
							 ___________________
	 						/	 		p(1−p) /
MARGIN OF ERROR 	 =     /	z ∗	√   ----- /
    					  /_______________n__/		 
							where,
									p the point estimate of the population proportion ,
									n is sample size, and 
									z is the z-critical value, stats.t.ppf(q = 0.975, df=24)

CONFIDENCE INTERVAL  = [ p  +  MARGIN OF ERROR , p -  MARGIN OF ERROR ]

z_critical = stats.norm.ppf(0.975)      # Record z-critical value
p = 0.192                               # Point estimate of proportion
n = 1000                                # Sample size
margin_of_error = z_critical * math.sqrt((p*(1-p))/n)
confidence_interval = (p - margin_of_error,  # Calculate the the interval
                       p + margin_of_error) 

(0.16758794241348748, 0.21641205758651252)

Calculate a confidence interval for a population proportion using the Python function tats.norm.interval()
stats.norm.interval(alpha = 0.95,    # Confidence level             
                   loc =  0.192,     # Point estimate of proportion
                   scale = math.sqrt((p*(1-p))/n))  # Scaling factor
(0.16758794241348748, 0.21641205758651252)


PROBABILITY DISTRIBUTIONS
http://hamelg.blogspot.com/2015/11/python-for-data-analysis-part-22.html
https://github.com/Gurubux/ML-Analysis-Steps/blob/master/BasicStatistics/ProbabilityDistributions/PROBABILITY_DISTRIBUTIONS.ipynb
------------------------------------------------------------------------
THE UNIFORM DISTRIBUTION
------------------------------------------------------------------------
The uniform distribution is a probability distribution where each value within a certain range is equally likely to occur and values 
outside of the range never occur.

import scipy.stats  as stats
uniform_data = stats.uniform.rvs(size=100000,  # Generate 100000 numbers
                                 loc = 0,      # From 0 
                                 scale=10)     # To 10
# Plot the distribution - UNIFORM
pd.DataFrame(uniform_data).plot(kind="density", figsize=(9,9), xlim=(-1,11))

#The area under a probability density curve is always equal to 1.

stats.distribution.rvs()
#generates random numbers from the specified distribution. The arguments to rvs() will vary depending on the type of distribution you're working with; in the case of the uniform distribution, we have to specify the starting and ending points and the size (number of random points to generate.).

# cumulative distribution function
stats.distribution.cdf()
# is used to determine the probability that an observation drawn from a distribution falls below a specified value
# In essence, cdf() gives you the area under the distribution's density curve to the left of a certain value on the x axis.
# For example, in the uniform distribution above, there is a 25% chance that an observation will be in the range 0 to 2.5 and a 75% chance it will fall in the range 2.5 to 10. We can confirm this with cdf():
stats.uniform.cdf(x=2.5,         # Cutoff value (quantile) to check
                  loc=0,         # Distribution start
                  scale=10)      # Distribution end
>>> 0.25

#Percent Point Function 
stats.distribution.ppf()
#is the inverse of cdf(): it returns the x axis cutoff value (quantile) associated with a given probability. For instance, if we want to know the cutoff value for which we have a 40% chance of drawing an observation below that value, we can use ppf():
stats.uniform.ppf(q=0.4,         # Probability cutoff
                  loc=0,         # Distribution start
                  scale=10)      # Distribution end
>>> 4.0     


#Probability density function
stats.distribution.pdf() 
#gives you the probability density (height of the distribution) at a given x value. Since the uniform distribution is flat, all x values within its range will have the same probability density and x values outside the range have a probability density of 0:
for x in range(-1,12,3):
    print("Density at x value " + str(x))
    print( stats.uniform.pdf(x, loc=0, scale=10) ) 
------------------------------------------------------------------------
GENERATING RANDOM NUMBERS AND SETTING THE SEED
------------------------------------------------------------------------
import random
random.randint(0,10)     # Get a random integer in the specified range
random.choice([2,4,6,9]) # Get a random element from a sequence
random.random()          # Get a real number between 0 and 1 

random.seed(12)  # Set the seed to an arbitrary value
print([random.uniform(0,10) for x in range(4)])
random.seed(12)  # Set the seed to the same value
print([random.uniform(0,10) for x in range(4)])
#pseudorandom.
------------------------------------------------------------------------
THE NORMAL or GAUSSIAN DISTRIBUTION
------------------------------------------------------------------------
CONTINUOUS probability distribution
A normal distribution is defined by its center (mean) and spread (standard deviation.). 
As a rule of thumb, about 
68% of the data lies within 1 standard deviation of the mean, 
95% lies within 2 standard deviations and 
99.7% lies within 3 standard deviations.

prob_under_minus1 = stats.norm.cdf(x= -1,  
                                loc = 0,               
                                scale= 1)     
prob_over_1 = 1 - stats.norm.cdf(x= 1,  
                                loc = 0,               
                                scale= 1) 
between_prob = 1-(prob_under_minus1+prob_over_1)
print(prob_under_minus1, prob_over_1, between_prob)
>>>0.158655253931 0.158655253931 0.682689492137
#The output shows that roughly 16% of the data generated by a normal distribution with mean 0 and standard deviation 1 is below -1, 16% is above 1 and 68% lies between -1 and 1, which agrees with the 68, 95, 99.7 rule.

# Plot normal distribution areas*

plt.rcParams["figure.figsize"] = (9,9)
                                  
plt.fill_between(x=np.arange(-4,-1,0.01), 
                 y1= stats.norm.pdf(np.arange(-4,-1,0.01)) ,
                 facecolor='red',
                 alpha=0.35)

plt.fill_between(x=np.arange(1,4,0.01), 
                 y1= stats.norm.pdf(np.arange(1,4,0.01)) ,
                 facecolor='red',
                 alpha=0.35)

plt.fill_between(x=np.arange(-1,1,0.01), 
                 y1= stats.norm.pdf(np.arange(-1,1,0.01)) ,
                 facecolor='blue',
                 alpha=0.35)

plt.text(x=-1.8, y=0.03, s= round(prob_under_minus1,3))
plt.text(x=-0.2, y=0.1, s= round(between_prob,3))
plt.text(x=1.4, y=0.03, s= round(prob_over_1,3))



print( stats.norm.ppf(q=0.025) ) # Find the quantile for the 2.5% cutoff # -1.95996398454 # ~ -2
print( stats.norm.ppf(q=0.975) ) # Find the quantile for the 97.5% cutoff # 1.95996398454 # ~  2
The quantile output above confirms that roughly 5% of the data lies more than 2 standard deviations from the mean.

*Note: a mean of 0 and standard deviation of 1 are default values for the normal distribution.

------------------------------------------------------------------------
THE BINOMIAL DISTRIBUTION
------------------------------------------------------------------------
DISCRETE probability distribution 
Models the outcomes of a given number of random trails of some experiment or event.

FAIR COINS FLIPPID --> 0.5 SUCCESS
fair_coin_flips = stats.binom.rvs(n=10,        # Number of flips per trial
                                  p=0.5,       # Success probability = 0.5
                                  size=10000)  # Number of trials
print( pd.crosstab(index="counts", columns= fair_coin_flips))

pd.DataFrame(fair_coin_flips).hist(range=(-0.5,10.5), bins=11)
>>>
col_0   0    1    2     3     4     5     6     7    8   9   10
row_0                                                          
counts   8  111  422  1181  1975  2453  2073  1224  450  94   9

BIASED COINS FLIPPID --> 0.8 SUCCESS
biased_coin_flips = stats.binom.rvs(n=10,      # Number of flips per trial
                                  p=0.8,       # Success probability 0.8
                                  size=10000)  # Number of trials
# Print table of counts
print( pd.crosstab(index="counts", columns= biased_coin_flips))
# Plot histogram
pd.DataFrame(biased_coin_flips).hist(range=(-0.5,10.5), bins=11)
col_0   2   3   4    5    6     7     8     9     10
row_0                                               
counts   1   4  53  258  834  1997  3076  2689  1088


#The cdf() function lets us check the probability of achieving a number of successes within a certain range:
stats.binom.cdf(k=5,        # Probability of k = 5 successes or less
                n=10,       # With 10 flips
                p=0.8)      # And success probability 0.8
>>>0.032793497599999964

1 - stats.binom.cdf(k=8,        # Probability of k = 9 successes or more
                    n=10,       # With 10 flips
                    p=0.8)      # And success probability 0.8
>>>0.37580963840000003




For continuous probability density functions, you use pdf() to check the probability density at a given x value. 
For DISCRETE DISTRIBUTIONS LIKE THE BINOMIAL, use stats.distribution.pmf() (probability mass function) to check the mass (proportion of observations) at given number of successes k:                    
stats.binom.pmf(k=5,        # Probability of k = 5 successes
                n=10,       # With 10 flips
                p=0.5)      # And success probability 0.5
>>>0.24609375000000025

stats.binom.pmf(k=8,        # Probability of k = 8 successes
                n=10,       # With 10 flips
                p=0.8)      # And success probability 0.8
>>>0.30198988799999998            



------------------------------------------------------------------------
THE GEOMETRIC AND EXPONENTIAL DISTRIBUTIONS
------------------------------------------------------------------------
The geometric and exponential distributions model THE TIME it takes for an event to occur.

The GEOMETRIC distribution is DISCRETE and models the number of trials it takes to achieve a success in repeated experiments with 
a given probability of success. 

The EXPONENTIAL distribution is a CONTINUOUS analog of the geometric distribution and models the amount of time you have to wait before 
an event occurs given a certain occurrence rate.

#Let's use the geom functions to model the number of trials it takes to get a success (heads) when flipping a fair coin:
random.seed(12)
flips_till_heads = stats.geom.rvs(size=10000,  # Generate geometric data
                                  p=0.5)       # With success prob 0.5
# Print table of counts
print( pd.crosstab(index="counts", columns= flips_till_heads))
# Plot histogram
pd.DataFrame(flips_till_heads).hist(range=(-0.5,max(flips_till_heads)+0.5)
                                    , bins=max(flips_till_heads)+1)
------------------------------------------------------------------------
THE POISSON DISTRIBUTION
------------------------------------------------------------------------
The Poisson distribution models the probability of seeing a certain number of successes within a time interval, where the time it takes for 
the next success is modeled by an exponential distribution.
he Poisson distribution can be used to model traffic, such as the number of arrivals a hospital can expect in a hour`s time or 
the number of emails you`d expect to receive in a week.

random.seed(12)
arrival_rate_1 = stats.poisson.rvs(size=10000,  # Generate Poisson data
                                   mu=1 )       # Average arrival time 1
# Print table of counts
print( pd.crosstab(index="counts", columns= arrival_rate_1))
# Plot histogram
pd.DataFrame(arrival_rate_1).hist(range=(-0.5,max(arrival_rate_1)+0.5)
                                    , bins=max(arrival_rate_1)+1)


random.seed(12)
arrival_rate_10 = stats.poisson.rvs(size=10000,  # Generate Poisson data
                                   mu=10 )       # Average arrival time 10
# Print table of counts
print( pd.crosstab(index="counts", columns= arrival_rate_10))
# Plot histogram
pd.DataFrame(arrival_rate_10).hist(range=(-0.5,max(arrival_rate_10)+0.5)
                                    , bins=max(arrival_rate_10)+1)


stats.poisson.cdf(k=5,     # Check the probability of 5 arrivals or less
                  mu=10)   # With arrival rate 10


stats.poisson.pmf(k=10,     # Check the prob f exactly 10 arrivals
                  mu=10)    # With arrival rate 10
CHI-SQUARED TESTS
STATISTICAL TEST FOR CATEGORICAL VARIABLES
http://hamelg.blogspot.com/2015/11/python-for-data-analysis-part-25-chi.html
------------------------------------------------------
CHI-SQUARED GOODNESS-OF-FIT TEST : stats.chisquare(f_obs= observed, f_exp= expected)  # Array of observed counts
------------------------------------------------------
In our study of t-tests, we introduced the one-way t-test to check whether a sample mean differs from the an expected (population) mean. The chi-squared goodness-of-fit test is an ANALOG of the one-way t-test for categorical variables : 
		"it tests whether the distribution of sample categorical data matches an expected distribution."
For example, you could use a chi-squared goodness-of-fit test to check whether the race demographics of members at your church or school match that of the entire U.S. population or whether the computer browser preferences of your friends match those of Internet uses as a whole.
When working with categorical data, the values themselves aren`t of much use for statistical testing because categories like "male", "female," and "other" have no mathematical meaning. Tests dealing with categorical variables are based on variable COUNTS instead of the actual value of the variables themselves.

Let`s generate some fake demographic data for U.S. and Minnesota and walk through the chi-square goodness of fit test to check whether they are different:
import numpy as np
import pandas as pd
import scipy.stats as stats

national = pd.DataFrame(["white"]*100000 + ["hispanic"]*60000 +\
                        ["black"]*50000 + ["asian"]*15000 + ["other"]*35000)
           

minnesota = pd.DataFrame(["white"]*600 + ["hispanic"]*300 + \
                         ["black"]*250 +["asian"]*75 + ["other"]*150)

national_table = pd.crosstab(index=national[0], columns="count")
minnesota_table = pd.crosstab(index=minnesota[0], columns="count")

print( "National")
print(national_table)
print(" ")
print( "Minnesota")
print(minnesota_table)
>>>
National
col_0      count
0               
asian      15000
black      50000
hispanic   60000
other      35000
white     100000
 
Minnesota
col_0     count
0              
asian        75
black       250
hispanic    300
other       150
white       600

Chi-squared tests are based on the so-called CHI-SQUARED STATISTIC. You calculate the chi-squared statistic with the following formula:
					    (observed−expected)²			(O − E)²
				=  Σ ( --------------------- )   = Σ ( ---------- )
							expected					   E


In the formula, observed is the actual observed count for each category and expected is the expected count based on the distribution of the population for the corresponding category. Let's calculate the chi-squared statistic for our data to illustrate:

observed = minnesota_table
national_ratios = national_table/len(national)  # Get population ratios
expected = national_ratios * len(minnesota)   # Get expected counts
chi_squared_stat = (((observed-expected)**2)/expected).sum()
print(chi_squared_stat)
>>>
col_0
count    18.194805
dtype: float64


#find the critical value for 95% confidence level and check the p-value of our result:
crit = stats.chi2.ppf(q = 0.95, # Find the critical value for 95% confidence*
                      df = 4)   # Df = number of variable categories - 1

print("Critical value")
print(crit)

p_value = 1 - stats.chi2.cdf(x=chi_squared_stat,  # Find the p-value
                             df=4)
print("P value")
print(p_value)
>>>0.00113047
"*Note: The chi-squared test assumes none of the expected counts are less than 5."
"""ddof : int, optional"
	Delta degrees of freedom”: adjustment to the degrees of freedom for the p-value. The p-value is computed using a chi-squared distribution with k - 1 - ddof degrees of freedom, where k is the number of observed frequencies. The default value of ddof is 0.
	axisint or None, optional"""

stats.chisquare(f_obs= observed,   # Array of observed counts
                f_exp= expected)   # Array of expected counts
>>> Power_divergenceResult(statistic=array([18.19480519]), pvalue=array([0.00113047]))
------------------------------------------------------
CHI-SQUARED TEST OF INDEPENDENCE : stats.chi2_contingency(observed= observed)
------------------------------------------------------
https://www.mathsisfun.com/data/chi-square-test.html
"The chi-squared test of independence tests whether two categorical variables are independent."
The test of independence is commonly used to determine whether variables like education, political views and other preferences vary based on demographic factors like gender, race and religion.
 For instance, the month you were born probably doesn`t tell you anything about which web browser you use, so we`d expect birth month and browser preference to be independent. 
 On the other hand, your month of birth might be related to whether you excelled at sports in school, so month of birth and sports performance might not be independent. 


np.random.seed(10)

# Sample data randomly at fixed probabilities
voter_race = np.random.choice(a= ["asian","black","hispanic","other","white"],
                              p = [0.05, 0.15 ,0.25, 0.05, 0.5],
                              size=1000)

# Sample data randomly at fixed probabilities
voter_party = np.random.choice(a= ["democrat","independent","republican"],
                              p = [0.4, 0.2, 0.4],
                              size=1000)

voters = pd.DataFrame({"race":voter_race, 
                       "party":voter_party})

voter_tab = pd.crosstab(voters.race, voters.party, margins = True)

voter_tab.columns = ["democrat","independent","republican","row_totals"]

voter_tab.index = ["asian","black","hispanic","other","white","col_totals"]

observed = voter_tab.ix[0:5,0:3]   # Get table without totals for later use
voter_tab


			democrat	independent	republican	row_totals
asian			21			7			32			60
black			65			25			64			154
hispanic		107			50			94			251
other			15			8			15			38
white			189			96			212			497
col_totals		397			186			417			1000



expected =  np.outer(voter_tab["row_totals"][0:5],
                     voter_tab.ix["col_totals"][0:3]) / 1000

expected = pd.DataFrame(expected)

expected.columns = ["democrat","independent","republican"]
expected.index = ["asian","black","hispanic","other","white"]

expected
			democrat	independent	republican
asian		23.820		11.160		25.020
black		61.138		28.644		64.218
hispanic	99.647		46.686		104.667
other		15.086		7.068		15.846
white		197.309		92.442		207.249
	

chi_squared_stat = (((observed-expected)**2)/expected).sum().sum()

print(chi_squared_stat)
>>>7.16932128016


crit = stats.chi2.ppf(q = 0.95, # Find the critical value for 95% confidence*
                      df = 8)   # *
"*The degrees of freedom for a test of independence equals the product of the number of categories in each variable minus 1. In this case we have a 5x3 table so df = 4x2 = 8. Multiply (rows − 1) by (columns − 1) "
print("Critical value")
print(crit)

p_value = 1 - stats.chi2.cdf(x=chi_squared_stat,  # Find the p-value
                             df=8)
print("P value")
print(p_value)
>>>
Critical value
15.5073130559
P value
0.518479392949


stats.chi2_contingency(observed= observed)
>>>
(7.1693212801620589,
 0.51847939294884204,
 8,
 array([[  23.82 ,   11.16 ,   25.02 ],
        [  61.138,   28.644,   64.218],
        [  99.647,   46.686,  104.667],
        [  15.086,    7.068,   15.846],
        [ 197.309,   92.442,  207.249]]))

"The output shows the chi-square statistic, the p-value and the degrees of freedom followed by the expected counts."
"As expected, given the high p-value, the test result does not detect a significant relationship between the variables."
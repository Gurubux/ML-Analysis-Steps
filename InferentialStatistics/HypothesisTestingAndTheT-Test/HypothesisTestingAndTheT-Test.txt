HYPOTHESIS TESTING AND THE T-TEST
Statistical hypothesis testing is a framework for determining whether observed data deviates from what is expected.
python`s scipy.stats library contains an array of functions that make it easy to carry out hypothesis tests.

http://scipy-lectures.org/packages/statistics/index.html#hypothesis-testing-comparing-two-groups
http://hamelg.blogspot.com/2015/11/python-for-data-analysis-part-24.html
------------------------------------------------------
HYPOTHESIS TESTING BASICS
------------------------------------------------------
Null Hypothesis:
	Statistical hypothesis tests are based a statement called the null hypothesis that assumes nothing interesting is going on between whatever variables you are testing.
	When a scientist wants to test for an effect (ie that one drug is more effective than another), they frame the problem in reverse. That is, rather than test for a difference, the scientist tests for sameness. If the scientist can disprove the sameness of the two drugs (the null hypothesis), they can confidently say that one is more effective than the other.
	For instance, if you wanted to test whether the average age of voters in your home state differs from the national average, the null hypothesis would be that there is no difference between the average ages.

 

Alternative Hypothesis:
	That something interesting is going on.
	The alternative hypothesis is simply the opposite of the null hypothesis. This is used to represent the condition when two things are different, such as when one clinical treatment is more effective. Generally, this is what the scientist wants to prove.
	For instance, the alternative hypothesis would be that the average age of voters in your state that does in fact differ from the national average.


Significance (alpha α):
	In order to decide if a result is meaningful, it is necessary to choose a threshold called ‘significance’. This number defines how extreme a result must be to cause us to doubt our null hypothesis. Usually the value of 0.05 (5%) is chosen for our significance. This can also be described as a confidence interval of 95%.
	Once you have the null and alternative hypothesis in hand, you choose a significance level.
	After carrying out a test, if the probability of getting a result as extreme as the one you observe due to chance is lower than the significance level, you reject the null hypothesis in favor of the alternative. 
	This probability of seeing a result as extreme or more extreme than the one observed is known as the p-value.

T-test:
	The T-test is a statistical test used to determine :
		1 - Whether a "NUMERIC" data sample differs significantly from the population (One-Sample T-Test) stats.ttest_1samp() or 
		2 - Whether two samples differ from one another(Two-Sample T-Test) stats.ttest_ind()
------------------------------------------------------
ONE-SAMPLE T-TEST : stats.ttest_1samp()
------------------------------------------------------
A one-sample t-test checks whether a sample mean differs from the population mean.

import numpy as np
import pandas as pd
import scipy.stats as stats
import matplotlib.pyplot as plt
import math

np.random.seed(6)

population_ages1 = stats.poisson.rvs(loc=18, mu=35, size=150000)
population_ages2 = stats.poisson.rvs(loc=18, mu=10, size=100000)
population_ages = np.concatenate((population_ages1, population_ages2))

minnesota_ages1 = stats.poisson.rvs(loc=18, mu=30, size=30)
minnesota_ages2 = stats.poisson.rvs(loc=18, mu=10, size=20)
minnesota_ages = np.concatenate((minnesota_ages1, minnesota_ages2))

print( population_ages.mean() )
print( minnesota_ages.mean() )
>>> 43.000112
	39.26

# conduct a one sample t-test stats.ttest_1samp()
stats.ttest_1samp(a= minnesota_ages,               # Sample data
                 popmean= population_ages.mean())  # Pop mean
>>> Ttest_1sampResult(statistic=-2.5742714883655027, pvalue=0.013118685425061678)
" t-value is equal to -2.574 .This test statistic tells us how much the sample mean deviates from the null hypothesis"


"If the t-statistic lies outside the quantiles of the t-distribution corresponding to our confidence level and degrees of freedom, we reject the null hypothesis. We can check the quantiles with stats.t.ppf():"
# Calculate t-value for Confidence Level 2.5%
stats.t.ppf(q=0.025,  # Quantile to check
            df=49)  # Degrees of freedom
>>> -2.0095752344892093

# Calculate t-value for Confidence Level 97.5%
stats.t.ppf(q=0.975,  # Quantile to check
            df=49)  # Degrees of freedom
>>> 2.0095752344892088

" According to our Ttest_1sampResult the t-test is -2.574 which lies outside 95% Confidence level t-distribution -2.0095 2.0095 We reject the null hypothesis"


# Calculate p-value from t-statistic or t-value
#We can calculate the chances of seeing a result as extreme as the one we observed (known as the p-value) by passing the t-statistic in as the quantile to the stats.t.cdf() function:
stats.t.cdf(x= -2.5742,      # T-test statistic
               df= 49) * 2   # Mupltiply by two for two tailed test*

>>>0.013121066545690117
"Note: The alternative hypothesis we are checking is whether the sample mean differs (is not equal to) the population mean. Since the sample could differ in either the positive or negative direction we multiply the by two."
"A p-value of 0.01311 means we'd expect to see data as extreme as our sample due to chance about 1.3% of the time if the null hypothesis was true. In this case, the p-value is lower than our significance level α (equal to 1-conf.level or 0.05) so we should reject the null hypothesis."
"THIS MEANS IF WE WERE TO CONSTRUCT A 95% CONFIDENCE INTERVAL FOR THE SAMPLE IT WOULD NOT CAPTURE POPULATION MEAN OF 43:"



sigma = minnesota_ages.std()/math.sqrt(50)  # Sample stdev/sample size
 # t-interval for 95% confindence level
stats.t.interval(0.95,                        # Confidence level
                 df = 49,                     # Degrees of freedom
                 loc = minnesota_ages.mean(), # Sample mean
                 scale= sigma)                # Standard dev estimate
>>>(36.369669080722176, 42.15033091927782)

"On the other hand, since there is a 1.3% chance of seeing a result this extreme due to chance, it is not significant at the 99% confidence level. This means if we were to construct a 99% confidence interval, it would capture the population mean:"
# t-interval for 99% confindence level
stats.t.interval(alpha = 0.99,                # Confidence level
                 df = 49,                     # Degrees of freedom
                 loc = minnesota_ages.mean(), # Sample mean
                 scale= sigma)                # Standard dev estimate
>>>(35.405479940921069, 43.114520059078927)

With a higher confidence level, we construct a wider confidence interval and increase the chances that it captures to true mean, thus making it less likely that we`ll reject the null hypothesis.

def normal_curve_confidence_shade(population_data,sample_data,sample_size):
  import numpy as np
  from sklearn.preprocessing import normalize
  np.random.seed(10)
  
  sample_means = []         # Make empty list to hold point estimates
  for x in range(200):         # Generate 200 samples
    sample = np.random.choice(a= sample_data, size=sample_size)
    sample_means.append( sample.mean() )
  
  fig=plt.figure(figsize=(15,9))
  
  plt.vlines(ymin=0, ymax=0.5,
           x=population_data.mean(), 
           linewidth=1.0,
           color="black",label=str('Population Mean %.2f'%population_data.mean()))
  
  plt.vlines(ymin=0, ymax=0.5,
           x=np.mean(sample_means), 
           linewidth=1.0,
           color="red",label=str('Sample Means Mean %.2f'%np.mean(sample_means)))
  
  plt.style.use('ggplot')
  mean=np.mean(sample_means)
  std=np.std(sample_means)
  
  x=np.arange(mean-6*std, mean+6*std,0.01)
  iq=stats.norm(mean,std)
  #plotting the normal curve
  plt.plot(x,stats.norm.pdf(x,mean,std),'black')
  intervals = stats.t.interval(alpha = 0.975,  # Confidence level
                 df = sample_size-1,                     # Degrees of freedom
                 loc = mean,                  # Sample mean
                 scale= sigma)
  px=np.arange(intervals[0],intervals[1],0.01)
  #plotting the normal curve
  plt.fill_between(px,iq.pdf(px),color='#1f77b4',label=str('97.5% Confidence {d[0]:.3f} to {d[1]:.3f}'.format(d=intervals)))
  
  intervals = stats.t.interval(alpha = 0.95,  # Confidence level
                 df = sample_size-1,                     # Degrees of freedom
                 loc = mean,                  # Sample mean
                 scale= sigma)
  px=np.arange(intervals[0],intervals[1],0.01)
  #plotting the normal curve
  plt.fill_between(px,stats.norm.pdf(px),color='#0a5386',label=str('95% Confidence {d[0]:.3f} to {d[1]:.3f}'.format(d=intervals)))
  
  intervals = stats.t.interval(alpha = 0.68,  # Confidence level
                 df = sample_size-1,                     # Degrees of freedom
                 loc = mean,                  # Sample mean
                 scale= sigma)
  px=np.arange(intervals[0],intervals[1],0.01)
  #Filling the 68% Confidence - 1 Z-critical
  plt.fill_between(px,iq.pdf(px),color='#173f5f',label=str('68% Confidence {d[0]:.3f} to {d[1]:.3f}'.format(d=intervals)))
  plt.legend()
  return sample_means
sample_means = normal_curve_confidence_shade(population_ages,minnesota_ages,100)  

def draw_z_score(x, cond, mu, sigma, title):
    y = stats.norm.pdf(x, mu, sigma)
    z = x[cond]
    plt.plot(x, y)
    #print(x,y,z)
    plt.fill_between(z, 0, stats.norm.pdf(z, mu, sigma))
    plt.title(title)
    plt.show()

x=np.arange(np.mean(sample_means)-6*np.std(sample_means), np.mean(sample_means)+6*np.std(sample_means),0.001)
intervals = stats.t.interval(alpha = 0.68,  # Confidence level
                 df = 100-1,                     # Degrees of freedom
                 loc = np.mean(sample_means),                  # Sample mean
                 scale= sigma)
z0,z1 = intervals
draw_z_score(x, (z0 < x) & (x < z1),np.mean(sample_means), np.std(sample_means), '-0.75<z<0.75')

x = np.arange(-3,3,0.001)
z0 = -0.75
draw_z_score(x, x<z0, 0, 1, 'z<-0.75')

x = np.arange(-3,3,0.001)
z0 = 0.75
draw_z_score(x, (-z0 < x) & (x < z0), 0, 1, '-0.75<z<0.75')

x = np.arange(-3,3,0.001)
z0 = 0.75
draw_z_score(x, x > z0, 0, 1, ' z> 0.75')

# Plotting density funtion of the Sample_mean`s mean and filling the curve 6 std left and right
plt.fill_between(x=np.arange(np.mean(sample_means)-6*np.std(sample_means), np.mean(sample_means)+6*np.std(sample_means),0.001), 
                 y1= stats.norm.pdf(np.arange(np.mean(sample_means)-6*np.std(sample_means), np.mean(sample_means)+6*np.std(sample_means),0.001),loc=np.mean(sample_means), scale=sigma),
                 facecolor='orange',
                 alpha=0.35)
# Plotting density funtion of the Sample_mean`s mean and filling the curvefor specific intervals
plt.fill_between(x=np.arange(intervals[0], intervals[1],0.001), 
                 y1= stats.norm.pdf(np.arange(intervals[0], intervals[1],0.001),loc=np.mean(sample_means), scale=sigma),
                 facecolor='red',
                 alpha=0.35)

------------------------------------------------------
TWO-SAMPLE T-TEST stats.ttest_ind()
------------------------------------------------------
A two-sample t-test investigates whether the means of two independent data samples differ from one another. In a two-sample test, the null hypothesis is that the means of both groups are the same. Unlike the one sample-test where we test against a known population parameter, the two sample test only involves sample means.

np.random.seed(12)
wisconsin_ages1 = stats.poisson.rvs(loc=18, mu=33, size=30)
wisconsin_ages2 = stats.poisson.rvs(loc=18, mu=13, size=20)
wisconsin_ages = np.concatenate((wisconsin_ages1, wisconsin_ages2))

print( wisconsin_ages.mean() )

stats.ttest_ind(a= minnesota_ages,
                b= wisconsin_ages,
                equal_var=False)    # Assume samples have equal variance?
>>>42.8
Ttest_indResult(statistic=-0.9775980071732967, pvalue=0.33096526170960816)

The test yields a p-value of 0.0907, which means there is a 9% chance we`d see sample data this far apart if the two groups tested are actually identical. If we were using a 95% confidence level we would fail to reject the null hypothesis, since the p-value is greater than the corresponding significance level of 5%.
------------------------------------------------------
PAIRED T-TEST : stats.ttest_rel()
------------------------------------------------------
The basic two sample t-test is designed for testing differences between independent groups. In some cases, you might be interested in testing differences between samples of the same group at different points in time. For instance, a hospital might want to test whether a weight-loss drug works by checking the weights of the same group patients before and after treatment. A paired t-test lets you check whether the means of samples from the same group differ.
We can conduct a paired t-test using the scipy function stats.ttest_rel().

np.random.seed(11)

before= stats.norm.rvs(scale=30, loc=250, size=100)

after = before + stats.norm.rvs(scale=5, loc=-1.25, size=100)

weight_df = pd.DataFrame({"weight_before":before,
                          "weight_after":after,
                          "weight_change":after-before})

weight_df.describe()             # Check a summary of the data
stats.ttest_rel(a = before,
                b = after)

>>>Ttest_relResult(statistic=2.5720175998568284, pvalue=0.011596444318439857)
The p-value in the test output shows that the chances of seeing this large of a difference between samples due to chance is just over 1%.
------------------------------------------------------
TYPE I AND TYPE II ERROR
------------------------------------------------------
Type I ERROR 	: "false positive" or "false hit".
Type II ERROR 	: "false negative" or "miss".

plt.figure(figsize=(12,10))

plt.fill_between(x=np.arange(-4,-2,0.01), 
                 y1= stats.norm.pdf(np.arange(-4,-2,0.01)) ,
                 facecolor='red',
                 alpha=0.35)

plt.fill_between(x=np.arange(-2,2,0.01), 
                 y1= stats.norm.pdf(np.arange(-2,2,0.01)) ,
                 facecolor='white',
                 alpha=0.35)

plt.fill_between(x=np.arange(2,4,0.01), 
                 y1= stats.norm.pdf(np.arange(2,4,0.01)) ,
                 facecolor='red',
                 alpha=0.5)

plt.fill_between(x=np.arange(-4,-2,0.01), 
                 y1= stats.norm.pdf(np.arange(-4,-2,0.01),loc=3, scale=2) ,
                 facecolor='white',
                 alpha=0.35)

plt.fill_between(x=np.arange(-2,2,0.01), 
                 y1= stats.norm.pdf(np.arange(-2,2,0.01),loc=3, scale=2) ,
                 facecolor='blue',
                 alpha=0.35)

plt.fill_between(x=np.arange(2,10,0.01), 
                 y1= stats.norm.pdf(np.arange(2,10,0.01),loc=3, scale=2),
                 facecolor='white',
                 alpha=0.35)

plt.text(x=-0.8, y=0.15, s= "Null Hypothesis")
plt.text(x=2.5, y=0.13, s= "Alternative")
plt.text(x=2.1, y=0.01, s= "Type 1 Error")
plt.text(x=-3.2, y=0.01, s= "Type 1 Error")
plt.text(x=0, y=0.02, s= "Type 2 Error")





lower_quantile = stats.norm.ppf(0.025)  # Lower cutoff value
upper_quantile = stats.norm.ppf(0.975)  # Upper cutoff value
print(lower_quantile,upper_quantile)
# Area under alternative, to the left the lower cutoff value
low = stats.norm.cdf(lower_quantile,    
                     loc=3,             
                     scale=2)

# Area under alternative, to the left the upper cutoff value
high = stats.norm.cdf(upper_quantile, 
                      loc=3, 
                      scale=2)          

# Area under the alternative, between the cutoffs (Type II error)
print(high,low)
high-low
>>>-1.9599639845400545 1.959963984540054
0.3015255120172813 0.006569450904958285
0.294956061112323